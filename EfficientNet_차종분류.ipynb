{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "EfficientNet_차종분류.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHhBtDNW6Qbw"
      },
      "source": [
        "#데이터 LOAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duQqPu2WiqwI",
        "outputId": "84c50476-1f15-42af-f30e-d6e2c9ae3a38"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5MmNaIIi2OT"
      },
      "source": [
        "!unzip -qq \"/content/drive/MyDrive/넥스트랩/dataset/0908_RealLast300.zip\" #개인경로로 바꾸기\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "L0EvmwOpiUVs"
      },
      "source": [
        "!pip install -U git+https://github.com/leondgarse/keras_efficientnet_v2\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import keras_efficientnet_v2 as efficientnet_v2\n",
        "from tensorflow.keras.layers import Dense, Input, Conv2D, Dropout, Flatten, Activation, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4WELxxG6b7S"
      },
      "source": [
        "#Image Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2YlivDTpiUVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a997fccb-e9fa-45e1-d9f8-8a17824054f3"
      },
      "source": [
        "train_path = '/content/split/train'\n",
        "val_path = '/content/split/valid'\n",
        "\n",
        "Batch_size = 64\n",
        "Input_size = (240,240)\n",
        "np.random.seed(27)\n",
        "epochs = 50\n",
        "num_classes = 322\n",
        "input_shape = (240,240,3)\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "                                      rescale=1/255.0,\n",
        "                                     zoom_range = 0.2\n",
        "                                     )\n",
        "valid_generator = ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "flow_train_gen = train_generator.flow_from_directory(train_path,\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  batch_size=Batch_size ,\n",
        "                                                  target_size =Input_size,\n",
        "                                                  shuffle=True)\n",
        "\n",
        "flow_val_gen = valid_generator.flow_from_directory(val_path,\n",
        "                                                   class_mode = 'categorical',\n",
        "                                                   batch_size=Batch_size, \n",
        "                                                   target_size= Input_size,\n",
        "                                                   shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 77280 images belonging to 322 classes.\n",
            "Found 19320 images belonging to 322 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3O7RrW9wiUV2"
      },
      "source": [
        "# steps 횟수를 구하기 위해 학습 데이터의 건수와 검증 데이터의 건수를 구함. steps = ceil(학습 데이터 건수/BATCH_SIZE)\n",
        "# 파일개수는 제너레이터 아래 기록된 path\n",
        "train_paths = 77280\n",
        "val_paths = 19320\n",
        "steps_per_epoch = int(np.ceil(train_paths / Batch_size))\n",
        "validation_steps = int(np.ceil(val_paths/ Batch_size))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqCoUQ3kYLW3"
      },
      "source": [
        "\n",
        "#모델구축"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSIt6iQPhQ5Q"
      },
      "source": [
        "def create_model(version = 'v1', model_type='b0', in_shape= (224,224,3), n_classes = 322):\n",
        " \n",
        "  if version == 'v1':\n",
        "    if model_type == 'b0':\n",
        "      base_model = efficientnet_v2.EfficientNetV1(model_type, input_shape=input_shape, num_classes=0, include_preprocessing=False,  pretrained='imagenet')\n",
        "    elif model_type == 'b1':\n",
        "      base_model = efficientnet_v2.EfficientNetV1(model_type, input_shape=input_shape, num_classes=0,include_preprocessing=False, pretrained='imagenet')\n",
        "  \n",
        "  elif version == 'v2':\n",
        "    if model_type == 'b0':\n",
        "      base_model = efficientnet_v2.EfficientNetV2(model_type, input_shape=input_shape, num_classes=0, include_preprocessing=False, pretrained='imagenet')\n",
        "    elif model_type == 'b1':\n",
        "      base_model = efficientnet_v2.EfficientNetV2(model_type, input_shape=input_shape, num_classes=0, include_preprocessing=False, pretrained='imagenet')\n",
        "\n",
        "  for layer in base_model.layers[:-30]: # just exclude last layer from copying\n",
        "    layer.trainable = False\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=in_shape))\n",
        "  model.add(base_model)\n",
        "  model.add(GlobalAveragePooling2D())\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBCFljpJiUVz"
      },
      "source": [
        "# EfficientNetV2 모델 생성. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpYEQqm_hTso"
      },
      "source": [
        "# callback\n",
        "save_dir = '/content/drive/MyDrive/' #개인경로\n",
        "checkpoint_name = f'0908_{epochs}-batch-{Batch_size}_B1_300.h5' #개인 save이름\n",
        "save_path = os.path.join(save_dir,checkpoint_name)\n",
        "\n",
        "checkpoint = ModelCheckpoint(save_path,\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='auto'\n",
        "                            )\n",
        "\n",
        "reduceLR = ReduceLROnPlateau(monitor='val_loss',\n",
        "                             factor=0.8,\n",
        "                             patience=3,\n",
        "                             min_lr = 0.01* 0.8 *0.8 * 0.8 * 0.8\n",
        "                             )\n",
        "\n",
        "earlystopping = EarlyStopping(monitor='val_loss',\n",
        "                              patience=10,\n",
        "                             )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuQWuDQBhkmP"
      },
      "source": [
        "top3_acc = tf.keras.metrics.TopKCategoricalAccuracy(\n",
        "    k=3, name=\"top3_acc\", dtype=None\n",
        ")\n",
        "model = create_model(version = 'v2', model_type='b1', in_shape= input_shape, n_classes = num_classes)\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['acc',top3_acc])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-UK_Lb7iLbg"
      },
      "source": [
        "history = model.fit(flow_train_gen, \n",
        "                    epochs=epochs, \n",
        "                    steps_per_epoch = steps_per_epoch,\n",
        "                    validation_data = flow_val_gen, \n",
        "                    validation_steps = validation_steps,\n",
        "                    callbacks = [earlystopping, checkpoint, reduceLR])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUUL-efz7BIf"
      },
      "source": [
        "model_name = '0908_nonfreeze_last300' #각자 정하고 싶은 이름\n",
        "model_path = os.path.join(save_dir,model_name)\n",
        "model.save(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O1bF8Es7Otk"
      },
      "source": [
        "weight_path = os.path.join(model_path,'0908_nonfreeze_last300_weight')\n",
        "model.save_weights(weight_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ojzh-peWd6ev"
      },
      "source": [
        "#모델 시각화\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIQUCIUA-kaA"
      },
      "source": [
        "#Plotting \n",
        "acc = history.history['acc'] \n",
        "val_acc = history.history['val_acc'] \n",
        "loss = history.history['loss'] \n",
        "val_loss = history.history['val_loss'] \n",
        "\n",
        "plt.figure(figsize=(8, 8)) \n",
        "\n",
        "plt.subplot(2, 1, 1) \n",
        "plt.plot(acc, label='Training Accuracy') \n",
        "plt.plot(val_acc, label='Validation Accuracy') \n",
        "plt.legend(loc='lower right') \n",
        "plt.ylabel('Accuracy') \n",
        "plt.ylim([min(plt.ylim()),1.0]) \n",
        "plt.title('Training and Validation Accuracy') \n",
        "\n",
        "plt.subplot(2, 1, 2) \n",
        "plt.plot(loss, label='Training Loss') \n",
        "plt.plot(val_loss, label='Validation Loss') \n",
        "plt.legend(loc='upper right') \n",
        "plt.ylabel('Cross Entropy') \n",
        "plt.ylim([0,10]) \n",
        "plt.title('Training and Validation Loss') \n",
        "plt.xlabel('epoch') \n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUve06ix-kaB"
      },
      "source": [
        "#ImageDataGenerator를 통해서 오토-레이블링 된 class를 가져옵니다.\n",
        "classes_dict = flow_train_gen.class_indices\n",
        "classes_dict = dict(map(reversed, classes_dict.items()))\n",
        "\n",
        "def predict_image(img_path):\n",
        "    # Read the image and resize it\n",
        "    img = image.load_img(img_path, target_size=(224,224))\n",
        "    # Convert it to a Numpy array with target shape.\n",
        "    x = image.img_to_array(img)\n",
        "    # Reshape\n",
        "    x = x.reshape((1,) + x.shape)\n",
        "    x /= 255.\n",
        "    result = model.predict([x])[0]\n",
        "\n",
        "    result = list(result)\n",
        "    \n",
        "    classname_list = []\n",
        "    pred_value_list = []\n",
        "    for _ in range(3) :\n",
        "      index= result.index(max(result))\n",
        "      classname_list.append(classes_dict[index])\n",
        "      pred_value_list.append(max(result))\n",
        "      result[index] = 0.\n",
        "\n",
        "    return classname_list, pred_value_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkPmeBMaENbe"
      },
      "source": [
        "###모델 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYvws4GI-kaB"
      },
      "source": [
        "test_car1_path = '/content/drive/MyDrive/넥스트랩/test_sample_image/MAH02950_1.jpg2.jpg' #test하고 싶은 image\n",
        "classnames1, values1 = predict_image(test_car1_path)\n",
        "\n",
        "for index, (classname, value) in enumerate(zip(classnames1, values1)) :\n",
        "  print(f'[{index}] class : {classname}\\npredict value : {value}\\n\\n')\n",
        "\n",
        "img = image.load_img(test_car1_path)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfP2KqxqM_Jw"
      },
      "source": [
        "test_car2_path = '/content/drive/MyDrive/넥스트랩/test_sample_image/MAH02950_793.jpg1.jpg' #test하고 싶은 image\n",
        "classnames2, values2 = predict_image(test_car2_path)\n",
        "\n",
        "for index, (classname, value) in enumerate(zip(classnames2, values2)) :\n",
        "  print(f'[{index}] class : {classname}\\npredict value : {value}\\n\\n')\n",
        "\n",
        "img = image.load_img(test_car2_path)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unqlFyCONQmj"
      },
      "source": [
        "classnames3, values3 = predict_image(test_car3_path)\n",
        "test_car3_path = '/content/drive/MyDrive/넥스트랩/test_sample_image/MAH02950_908.jpg3.jpg' #test하고 싶은 image\n",
        "\n",
        "for index, (classname, value) in enumerate(zip(classnames3, values3)) :\n",
        "  print(f'[{index}] class : {classname}\\npredict value : {value}\\n\\n')\n",
        "\n",
        "img = image.load_img(test_car3_path)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqYaHEXFOPl7"
      },
      "source": [
        "test_car4_path = '/content/drive/MyDrive/넥스트랩/test_sample_image/MAH02950_561.jpg2.jpg' #test하고 싶은 image\n",
        "\n",
        "classnames4, values4 = predict_image(test_car4_path)\n",
        "\n",
        "for index, (classname, value) in enumerate(zip(classnames4, values4)) :\n",
        "  print(f'[{index}] class : {classname}\\npredict value : {value}\\n\\n')\n",
        "\n",
        "img = image.load_img(test_car4_path)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slXu-ov4OogZ"
      },
      "source": [
        "test_car4_path = '/content/drive/MyDrive/넥스트랩/test_sample_image/MAH02950_260.jpg0.jpg' #test하고 싶은 image\n",
        "classnames4, values4 = predict_image(test_car4_path)\n",
        "\n",
        "for index, (classname, value) in enumerate(zip(classnames4, values4)) :\n",
        "  print(f'[{index}] class : {classname}\\npredict value : {value}\\n\\n')\n",
        "\n",
        "img = image.load_img(test_car4_path)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkPtiPqLlKsQ"
      },
      "source": [
        "###히트맵 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqeGHEO2lAPm"
      },
      "source": [
        "def make_gradcam_heatmap(img_array, model, pre_trained,last_conv_layer_name, classifier_layer_names):\n",
        "    \n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer\n",
        "    last_conv_layer  = model.get_layer(pre_trained).get_layer(last_conv_layer_name)\n",
        "    conv_model       = keras.Model(model.get_layer(pre_trained).inputs, last_conv_layer.output)\n",
        "    # Second, we create a model that maps the activations of the last conv\n",
        "    # layer to the final class predictions\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    \n",
        "    for layer_name in classifier_layer_names:\n",
        "        x = model.get_layer(layer_name)(x)\n",
        "\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer  \n",
        "    with tf.GradientTape() as tape:\n",
        "        # Compute activations of the last conv layer and make the tape watch it\n",
        "        last_conv_layer_output = conv_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        \n",
        "        # Compute class predictions\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # This is the gradient of the top predicted class with regard to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "    \n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "\n",
        "    # is our saliency heatmap of class activation\n",
        "    saliency = np.mean(last_conv_layer_output, axis=-1)\n",
        "    saliency = np.maximum(saliency, 0) / np.max(saliency)\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    \n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # The channel-wise mean of the resulting feature map\n",
        "    # is our grad_cam heatmap of class activation\n",
        "    grad_cam = np.mean(last_conv_layer_output, axis=-1)\n",
        "    grad_cam = np.maximum(grad_cam, 0) / np.max(grad_cam)\n",
        "\n",
        "    return grad_cam, saliency"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SWucsxilAPn"
      },
      "source": [
        "def merge_with_heatmap(original_img, heatmap):\n",
        "    original_img = np.array(original_img)\n",
        "    resized_heatmap=resize(heatmap, (240, 240))\n",
        "    resized_heatmap = np.uint8(255*resized_heatmap)\n",
        "    resized_heatmap = cv2.applyColorMap(resized_heatmap, cv2.COLORMAP_JET)\n",
        "    #resized_heatmap = cv2.cvtColor(resized_heatmap, cv2.COLOR_RGB2BGR)\n",
        "    return cv2.addWeighted(resized_heatmap, 0.7, original_img, 0.5, 6)\n",
        "\n",
        "def convert_to_heatmap(heatmap):\n",
        "    heatmap = np.uint8(255*heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    return cv2.cvtColor(heatmap, cv2.COLOR_RGB2BGR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unENJ3MjlAPn"
      },
      "source": [
        "def show_hotmap (img, heatmap, title='Heatmap', alpha=0.6, cmap='jet', axisOnOff='off'):\n",
        "    '''\n",
        "    img     :    Image\n",
        "    heatmap :    2d narray\n",
        "    '''\n",
        "    resized_heatmap=resize(heatmap, img.size)\n",
        "    \n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(img)\n",
        "    ax.imshow(resized_heatmap, alpha=alpha, cmap=cmap)\n",
        "    plt.axis(axisOnOff)\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHhtFmh5lAPn"
      },
      "source": [
        "def prepare_single_input(img_path, target_size=(224, 224)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img = image.img_to_array(img)\n",
        "    img /= 255.\n",
        "    img = np.expand_dims(img, axis= 0) # (1, 224, 224, 3)\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3wKk69JlAPo"
      },
      "source": [
        "def predict_image(Mymodel, img_path, top_k_num = 3):\n",
        "    image = prepare_single_input(img_path, target_size = (240, 240))\n",
        "    result = Mymodel.predict([image])[0]\n",
        "\n",
        "    result = list(result)\n",
        "    \n",
        "    classname_list = []\n",
        "    pred_value_list = []\n",
        "    for _ in range(top_k_num) :\n",
        "      index= result.index(max(result))\n",
        "      classname_list.append(classes_dict[index])\n",
        "      pred_value_list.append(max(result))\n",
        "      result[index] = 0.\n",
        "\n",
        "    return classname_list, pred_value_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjTylPsFlAPp",
        "outputId": "768869bf-30f0-480e-94a6-701403f8dfa5"
      },
      "source": [
        "######################################################################################\n",
        "#defalut classifier_layer_names #기본 classifier_layer입니다.\n",
        "#classifier_layer_names =  ['global_average_pooling2d', 'dropout', 'dense']\n",
        "classifier_layers =  model.layers[-3:]\n",
        "classifier_layer_names = []\n",
        "for layer in classifier_layers:\n",
        "    classifier_layer_names.append(layer.name)\n",
        "last_conv_layer_name   = 'post_swish'\n",
        "pre_train= 'EfficientNetV2'\n",
        "Top_K = 1\n",
        "\n",
        "true_cnt = 0\n",
        "false_cnt = 0\n",
        "\n",
        "#####################################################################################\n",
        "image_paths = glob.glob('./data/test/dataset/**/*.jpg') #경로 설정해주기\n",
        "for path in tqdm(image_paths, total = len(image_paths)) :\n",
        "    img = Image.open(path).resize(size=input_shape[:2])  \n",
        "    img_array = prepare_single_input(path, input_shape[:2])\n",
        "    #test\n",
        "    grad_cam, saliency = make_gradcam_heatmap(img_array, model, pre_train,last_conv_layer_name, classifier_layer_names)\n",
        "    pred_classnames, pred_values = predict_image(model, path)\n",
        "\n",
        "\n",
        "    grad_cam_merge = merge_with_heatmap(img, grad_cam)\n",
        "    saliency_merge = merge_with_heatmap(img, saliency)\n",
        "\n",
        "    grad_cam = convert_to_heatmap(grad_cam)\n",
        "    saliency = convert_to_heatmap(saliency)\n",
        "\n",
        "    #save\n",
        "\n",
        "    #./data/test/dataset\\BMW_SUV_X5_2019-2020\\MAH02945_1017.jpg1.jpg -> BMW_SUV_X5_2019-2020\n",
        "    true_classname = path.split('\\\\')[1]\n",
        "\n",
        "    for index, pred_classname in enumerate(pred_classnames) :\n",
        "        #BMW/SUV_X5/2019-2020 -> BMW_SUV_X5_2019-2020 True_class와 맞추기 위해서.\n",
        "        pred_classnames[index] = pred_classname.replace('/','_')\n",
        "\n",
        "    #pred_values안에 0.1이 있다면 True 그렇지 않다면 False인 리스트 생성\n",
        "    flag_pred_value = list(map(lambda x : True if x >= 0.1 else False, pred_values))\n",
        "\n",
        "    #실제 클래스와 예측 클래스가 일치하면, 그리고 predict_value가 0.1이상이라면 실행\n",
        "    #Select save path True or False\n",
        "    if (true_classname in pred_classnames) & (True in flag_pred_value) : \n",
        "        true_cnt+=1\n",
        "        #./data/test/dataset\\BMW_SUV_X5_2019-2020\\MAH02945_1017.jpg1.jpg -> ./data/test/result/true/MAH02945_1017.jpg1.jpg\n",
        "        split_paths = path.split('\\\\')\n",
        "        save_path = split_paths[0].replace('dataset','result') +'/' + 'true' + '/' + split_paths[-1]\n",
        "    else : \n",
        "        false_cnt+=1\n",
        "        #./data/test/dataset\\BMW_SUV_X5_2019-2020\\MAH02945_1017.jpg1.jpg -> ./data/test/result/false/MAH02945_1017.jpg1.jpg\n",
        "        split_paths = path.split('\\\\')\n",
        "        save_path = split_paths[0].replace('dataset','result') +'/' + 'false' + '/' + split_paths[-1]\n",
        "\n",
        "    #Save original image \n",
        "    img.save(save_path)\n",
        "    #./data/test_result/true/MAH02945_1017.jpg1.jpg -> ./data/test_result/true or false/MAH02945_1017.jpg1.txt\n",
        "    tmp_path = save_path[:-3] + 'txt'\n",
        "    with open(tmp_path, \"w\", encoding=\"UTF-8\") as f:\n",
        "        f.write(f\"[실제 클래스]\\n\")\n",
        "        f.write(f\"{true_classname}\\n\")\n",
        "        f.write(f\"[예측 클래스 Top 3]\\n\")\n",
        "        f.write(f\"{pred_classnames[0]}, 예측률 : {pred_values[0]}\\n\")\n",
        "        f.write(f\"{pred_classnames[1]}, 예측률 : {pred_values[1]}\\n\")\n",
        "        f.write(f\"{pred_classnames[2]}, 예측률 : {pred_values[2]}\\n\")\n",
        "\n",
        "    #Save grad_cam image\n",
        "    #./data/test_result/true/MAH02945_1017.jpg1.jpg -> ./data/test_result/true or false/MAH02945_1017.jpg1_gc.jpg\n",
        "    tmp_path = save_path[:-4] + '_gc.jpg'\n",
        "    plt.figure(figsize=(input_shape[0] / 100, input_shape[0] / 100))\n",
        "    plt.imshow(grad_cam)\n",
        "    plt.axis('off'), plt.xticks([]), plt.yticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(left = 0, bottom = 0, right = 1, top = 1, hspace = 0, wspace = 0)\n",
        "    plt.savefig(tmp_path, bbox_inces='tight', pad_inches=0, dpi=100)\n",
        "    plt.close()\n",
        "    \n",
        "\n",
        "    #Save saliency image\n",
        "    #./data/test_result/true/MAH02945_1017.jpg1.jpg -> ./data/test_result/true or false/MAH02945_1017.jpg1_sa.jpg\n",
        "    tmp_path = save_path[:-4] + '_sa.jpg'\n",
        "    plt.figure(figsize=(input_shape[0] / 100, input_shape[0] / 100))\n",
        "    plt.imshow(saliency)\n",
        "    plt.axis('off'), plt.xticks([]), plt.yticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(left = 0, bottom = 0, right = 1, top = 1, hspace = 0, wspace = 0)\n",
        "    plt.savefig(tmp_path, bbox_inces='tight', pad_inches=0, dpi=100)\n",
        "    plt.close()\n",
        "    \n",
        "\n",
        "    #Save grad_cam-Merge image\n",
        "    #./data/test_result/true/MAH02945_1017.jpg1.jpg -> ./data/test_result/true or false/MAH02945_1017.jpg1_gcm.jpg\n",
        "    tmp_path = save_path[:-4] + '_gcm.jpg'\n",
        "    cv2.imwrite(tmp_path, grad_cam_merge)\n",
        "\n",
        "    #Save saliency-Merge image\n",
        "    #./data/test_result/true/MAH02945_1017.jpg1.jpg -> ./data/test_result/true or false/MAH02945_1017.jpg1_sam.jpg\n",
        "    tmp_path = save_path[:-4] + '_sam.jpg'\n",
        "    cv2.imwrite(tmp_path, saliency_merge)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 836/836 [04:04<00:00,  3.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0dFdKXilAPp"
      },
      "source": [
        "acc = true_cnt / (true_cnt+false_cnt)\n",
        "print(f\"Top{Top_K} Acc : {round(acc,2)}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}